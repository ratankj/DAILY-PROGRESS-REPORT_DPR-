{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orgwise_Privilege_group_status_SB=pd.read_csv(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\RC_DC_TRACKER\\RC_DC_INPUT_FILE\\Orgwise_Privilege_group_status_SB.csv\")\n",
    "Orgwise_Privilege_group_status_NB=pd.read_csv(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\RC_DC_TRACKER\\RC_DC_INPUT_FILE\\Orgwise_Privilege_group_status_NB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIVISION_MASTER_TABLE data is done\n",
      "WEEKLY_REPORT\n"
     ]
    }
   ],
   "source": [
    "# DIVISION TABLE\n",
    "\n",
    "DIVISION_MASTER_TABLE =  pd.read_csv(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\WEEKLY REPORT\\INPUT FILE\\DIVISION_MASTER.CSV\")\n",
    "print(\"DIVISION_MASTER_TABLE data is done\")\n",
    "WEEKLY_REPORT =  pd.read_excel(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\WEEKLY REPORT\\INPUT FILE\\Division Master table.xlsx\")\n",
    "WEEKLY_REPORT.to_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_weekly_report\\WEEKLY_REPORT.csv\",index=False)\n",
    "WEEKLY_REPORT=pd.read_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_weekly_report\\WEEKLY_REPORT.csv\")\n",
    "\n",
    "\n",
    "print('WEEKLY_REPORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HES DATA\n",
    "\n",
    "Infrastructure_Devices_NB=pd.read_csv(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\WEEKLY REPORT\\INPUT FILE\\Infrastructure_Devices_NB.csv\",sep=';')\n",
    "Infrastructure_Devices_SB=pd.read_csv(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\WEEKLY REPORT\\INPUT FILE\\Infrastructure_Devices_SB.csv\",sep=';')\n",
    "\n",
    "Infrastructure_Devices_NB.drop(columns=['Unnamed: 13'],axis=1,inplace=True)\n",
    "Infrastructure_Devices_SB.drop(columns=['Unnamed: 13'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 data is done\n",
      "2022 data is done\n",
      "2023 data is done\n",
      "2024 data is done\n"
     ]
    }
   ],
   "source": [
    "# METER COMPILATION DATA\n",
    "\n",
    "\n",
    "COMPILED_METER_2021=pd.read_excel(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\RC_DC_TRACKER\\COMPILED_METER_INSTALLATION_ALL\\compiled_Data_2021.xlsx\")\n",
    "print(\"2021 data is done\")\n",
    "COMPLIED_METER_2022=pd.read_excel(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\RC_DC_TRACKER\\COMPILED_METER_INSTALLATION_ALL\\compiled_Data_2022.xlsx\")\n",
    "print(\"2022 data is done\")\n",
    "COMPLIED_METER_2023=pd.read_excel(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\RC_DC_TRACKER\\COMPILED_METER_INSTALLATION_ALL\\compiled_Data_2023.xlsx\")\n",
    "print(\"2023 data is done\")\n",
    "COMPLIED_METER_2024=pd.read_excel(r\"C:\\Users\\Ratan Kumar Jha\\Desktop\\Daily progress report\\RC_DC_TRACKER\\COMPILED_METER_INSTALLATION_ALL\\complied_Data_2024.xlsx\")\n",
    "print(\"2024 data is done\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#convert to csv\n",
    "\n",
    "COMPILED_METER_2021.to_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPILED_METER_2021.csv\",index=False)\n",
    "COMPLIED_METER_2022.to_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPLIED_METER_2022.csv\",index=False)\n",
    "COMPLIED_METER_2023.to_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPLIED_METER_2023.csv\",index=False)\n",
    "COMPLIED_METER_2024.to_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPLIED_METER_2024.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ratan Kumar Jha\\AppData\\Local\\Temp\\ipykernel_34568\\567392238.py:1: DtypeWarning: Columns (7,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  COMPILED_METER_2021=pd.read_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPILED_METER_2021.csv\")\n",
      "C:\\Users\\Ratan Kumar Jha\\AppData\\Local\\Temp\\ipykernel_34568\\567392238.py:2: DtypeWarning: Columns (7,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  COMPLIED_METER_2022=pd.read_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPLIED_METER_2022.csv\")\n",
      "C:\\Users\\Ratan Kumar Jha\\AppData\\Local\\Temp\\ipykernel_34568\\567392238.py:3: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  COMPLIED_METER_2023=pd.read_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPLIED_METER_2023.csv\")\n"
     ]
    }
   ],
   "source": [
    "COMPILED_METER_2021=pd.read_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPILED_METER_2021.csv\")\n",
    "COMPLIED_METER_2022=pd.read_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPLIED_METER_2022.csv\")\n",
    "COMPLIED_METER_2023=pd.read_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPLIED_METER_2023.csv\")\n",
    "COMPLIED_METER_2024=pd.read_csv(r\"C:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\output_folder_data_compliation\\COMPLIED_METER_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 38.0 MiB for an array with shape (3, 1661856) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# compiled data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ALL_DATA_COMPILATION_MERGE_2023 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCOMPILED_METER_2021\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOMPLIED_METER_2022\u001b[49m\u001b[43m,\u001b[49m\u001b[43mCOMPLIED_METER_2023\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# DATA COMPILATION MERGE\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ALL_DATA_COMPILATION_MERGE \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([ALL_DATA_COMPILATION_MERGE_2023,COMPLIED_METER_2024], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    381\u001b[0m     objs,\n\u001b[0;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    391\u001b[0m )\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    678\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 680\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    684\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\PYTHON\\EDF_CODE_AUTOMATION_PYTHON\\DAILY-PROGRESS-REPORT_DPR-\\venv\\lib\\site-packages\\pandas\\core\\internals\\concat.py:177\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    167\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# expected \"Union[_SupportsArray[dtype[Any]],\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ea_compat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 38.0 MiB for an array with shape (3, 1661856) and data type object"
     ]
    }
   ],
   "source": [
    "# compiled data\n",
    "ALL_DATA_COMPILATION_MERGE_2023 = pd.concat([COMPILED_METER_2021, COMPLIED_METER_2022,COMPLIED_METER_2023], ignore_index=True)\n",
    "\n",
    "# DATA COMPILATION MERGE\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE = pd.concat([ALL_DATA_COMPILATION_MERGE_2023,COMPLIED_METER_2024], ignore_index=True)\n",
    "\n",
    "\n",
    "# changes in dataset like :- UPPER, SPACE REMOVAL , DATATYPE\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE = ALL_DATA_COMPILATION_MERGE.astype(str)\n",
    "ALL_DATA_COMPILATION_MERGE.columns = ALL_DATA_COMPILATION_MERGE.columns.str.upper()\n",
    "ALL_DATA_COMPILATION_MERGE = ALL_DATA_COMPILATION_MERGE.apply(lambda x: x.str.strip() if x.dtype == 'O' else x)\n",
    "ALL_DATA_COMPILATION_MERGE.columns = ALL_DATA_COMPILATION_MERGE.columns.str.strip()\n",
    "\n",
    "\n",
    "# CONVERT INTO DATETIME, SORT VALUES AND DROP DUPLICATES\n",
    "ALL_DATA_COMPILATION_MERGE['REPLACEMENT DATE'] = pd.to_datetime(ALL_DATA_COMPILATION_MERGE['REPLACEMENT DATE'])\n",
    "ALL_DATA_COMPILATION_MERGE.sort_values(by=['REPLACEMENT DATE'],ascending=False,inplace= True)\n",
    "\n",
    "# drop duplicate keep first , other drop\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE.drop_duplicates(subset=['NEW METER NO'], keep='first', inplace=True, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom function to update meter numbers\n",
    "def update_meter_number(meter_number):\n",
    "    if meter_number.startswith('GP') or meter_number.startswith('GL'):\n",
    "        return 'GOE' + meter_number\n",
    "    elif meter_number.startswith('LT'):\n",
    "        return 'LNT' + meter_number\n",
    "    else:\n",
    "        return meter_number\n",
    "\n",
    "# Apply the custom function to each element in the 'METER NO.' column\n",
    "ALL_DATA_COMPILATION_MERGE['FULL_METER_NUMBER'] = ALL_DATA_COMPILATION_MERGE['NEW METER NO'].apply(update_meter_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping column\n",
    "\n",
    "DIVISION_MASTER_TABLE.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Division_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETTIAH</td>\n",
       "      <td>BETTIAH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Division Division_new\n",
       "0  BETTIAH      BETTIAH"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEEKLY_REPORT.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division  data count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIVISION_MASTER_TABLE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Division_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETTIAH</td>\n",
       "      <td>BETTIAH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Division Division_new\n",
       "0  BETTIAH      BETTIAH"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEEKLY_REPORT.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DIVISION_MASTER_TABLE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mDIVISION_MASTER_TABLE\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DIVISION_MASTER_TABLE' is not defined"
     ]
    }
   ],
   "source": [
    "DIVISION_MASTER_TABLE.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper\n",
    "\n",
    "DIVISION_MASTER_TABLE['Division_new_check'] =  DIVISION_MASTER_TABLE['Division_new_check'].str.upper()\n",
    "WEEKLY_REPORT['Division'] =  WEEKLY_REPORT['Division'].str.upper()\n",
    "WEEKLY_REPORT['Division_new'] =  WEEKLY_REPORT['Division_new'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "After_merge_check_data = pd.merge(DIVISION_MASTER_TABLE['Division_new_check'],WEEKLY_REPORT['Division'],left_on=['Division_new_check'],right_on=['Division'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "After_merge_check_data['Division'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working on DIVISION COLUMN in compilation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SL</th>\n",
       "      <th>SECTION ID</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>WO STATUS</th>\n",
       "      <th>WORK ORDER TYPE</th>\n",
       "      <th>NEW METER NO</th>\n",
       "      <th>CONSUMER ID</th>\n",
       "      <th>INSTALLATION_NUMBER</th>\n",
       "      <th>NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>TOWN</th>\n",
       "      <th>VENDOR NAME</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>VENDOR_MANAGER</th>\n",
       "      <th>VENDOR_PLANNER</th>\n",
       "      <th>DUPLICATE</th>\n",
       "      <th>SECTION_ID</th>\n",
       "      <th>FULL_METER_NUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61053</td>\n",
       "      <td>nan</td>\n",
       "      <td>NBPDCL-West</td>\n",
       "      <td>nan</td>\n",
       "      <td>SSR Complete</td>\n",
       "      <td>SSR</td>\n",
       "      <td>GL9092936</td>\n",
       "      <td>400912857.0</td>\n",
       "      <td>5002305304</td>\n",
       "      <td>REETA  DEVI</td>\n",
       "      <td>...</td>\n",
       "      <td>West Champaran</td>\n",
       "      <td>edf</td>\n",
       "      <td>SEC-BETTIAH -II</td>\n",
       "      <td>BETTIAH</td>\n",
       "      <td>Open</td>\n",
       "      <td>edf_bet_vm_ssi</td>\n",
       "      <td>edf_bet_vp_ssi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>EBCAB</td>\n",
       "      <td>GOEGL9092936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60411</td>\n",
       "      <td>nan</td>\n",
       "      <td>Pesu-West</td>\n",
       "      <td>End To End</td>\n",
       "      <td>VP NMI Approved</td>\n",
       "      <td>New Meter Installation</td>\n",
       "      <td>GL9099781</td>\n",
       "      <td>nan</td>\n",
       "      <td>5004023488</td>\n",
       "      <td>Pankaj Kumar</td>\n",
       "      <td>...</td>\n",
       "      <td>Patna</td>\n",
       "      <td>TechMate</td>\n",
       "      <td>SEC-KHAJPURA</td>\n",
       "      <td>ASHIYANA</td>\n",
       "      <td>Closed</td>\n",
       "      <td>tech_vm_patna</td>\n",
       "      <td>tech_vp_pat05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ABGBA</td>\n",
       "      <td>GOEGL9099781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SL SECTION ID      CLUSTER    CATEGORY        WO STATUS  \\\n",
       "0  61053        nan  NBPDCL-West         nan     SSR Complete   \n",
       "1  60411        nan    Pesu-West  End To End  VP NMI Approved   \n",
       "\n",
       "          WORK ORDER TYPE NEW METER NO  CONSUMER ID INSTALLATION_NUMBER  \\\n",
       "0                     SSR    GL9092936  400912857.0          5002305304   \n",
       "1  New Meter Installation    GL9099781          nan          5004023488   \n",
       "\n",
       "           NAME  ...            TOWN VENDOR NAME          SECTION  DIVISION  \\\n",
       "0   REETA  DEVI  ...  West Champaran         edf  SEC-BETTIAH -II   BETTIAH   \n",
       "1  Pankaj Kumar  ...           Patna    TechMate     SEC-KHAJPURA  ASHIYANA   \n",
       "\n",
       "   STATUS  VENDOR_MANAGER  VENDOR_PLANNER DUPLICATE SECTION_ID  \\\n",
       "0    Open  edf_bet_vm_ssi  edf_bet_vp_ssi       1.0      EBCAB   \n",
       "1  Closed   tech_vm_patna   tech_vp_pat05       1.0      ABGBA   \n",
       "\n",
       "  FULL_METER_NUMBER  \n",
       "0      GOEGL9092936  \n",
       "1      GOEGL9099781  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_DATA_COMPILATION_MERGE.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into upper char\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the division_name old name to new name\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BAGAHA'], 'BAGHA')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['ARA'], 'ARRAH')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['ARRAH'], 'ARRAH')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BHABUA'], 'BHABHUA')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BHAGALPUR(E)'], 'BHAGALPUR')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BHAGALPUR(U)'], 'BHAGALPUR')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BHAGALPUR(URBAN)'], 'BHAGALPUR')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BIHARSHARIF'], 'BIHARSARIF')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BIHARSHARIFF'], 'BIHARSARIF')\n",
    "\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['CHAPRA(E)'], 'CHAPRA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['CHAPRA(EAST)'], 'CHAPRA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['CHAPRA(W)'], 'CHAPRA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['CHAPRA(WEST)'], 'CHAPRA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['MAHARAJGANJ'], 'CHAPRA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['MIRGANJ'], 'CHAPRA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['SONPUR'], 'CHAPRA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['CHAPRA'], 'CHAPRA')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['DARBHANAGA(U)'], 'DARBHANGA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['DARBHANGA(R)'], 'DARBHANGA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['DARBHANGA'], 'DARBHANGA')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['DALSINGHSARAI'], 'DALSINGSARAI')\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['DEHRI'], 'DEHRIONSONE')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['DEHRIONSONE'], 'DEHRIONSONE')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['EAST CHAMPARAN'], 'MOTIHARI')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['GAYA(R)'], 'GAYA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['GAYA(U)'], 'GAYA')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['GOPALGUNJ'], 'GOPALGANJ')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['HAZIPUR'], 'HAJIPUR')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['JEHANABAD'], 'JAHANABAD')\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['MASAURI'], 'MASAURHI')\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['MUZAFFARPUR(E)'], 'MUZAFFARPUR')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['MUZAFFARPUR(U-I)'], 'MUZAFFARPUR')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['MUZAFFARPUR(U-II)'], 'MUZAFFARPUR')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['MUZAFFARPUR(W)'], 'MUZAFFARPUR')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['NAUGACHHIYA'], 'NAUGACHIA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['NAWADAH'], 'NAWADA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['PATLIPUTRA'], 'PATALIPUTRA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['PESU WEST'], 'DANAPUR')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['PIRO'], 'SASARAM')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['PURNEA (EAST)'], 'PURNEA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['PURNEA(E)'], 'PURNEA')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['PURNEA(W)'], 'PURNEA')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['ROHTAS'], 'SASARAM')\n",
    "\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['EAST CHAMPARAN'], 'MOTIHARI')\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['WEST CHAMPARAN'], 'MOTIHARI')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['KHEMICHAK'], 'PATNA')\n",
    "\n",
    "\n",
    "ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['DHAKA'], 'DHAKA')\n",
    "\n",
    "#ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BAGAHA'], 'BAGHA')\n",
    "#ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BAGAHA'], 'BAGHA')\n",
    "#ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BAGAHA'], 'BAGHA')\n",
    "#ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BAGAHA'], 'BAGHA')\n",
    "#ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BAGAHA'], 'BAGHA')\n",
    "#ALL_DATA_COMPILATION_MERGE['DIVISION'] = ALL_DATA_COMPILATION_MERGE['DIVISION'].replace(['BAGAHA'], 'BAGHA') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly report division table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEEKLY_REPORT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVISION_MASTER_TABLE_NEW_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop division\n",
    "\n",
    "WEEKLY_REPORT.drop(['Division'], axis=1, inplace=True)\n",
    "\n",
    "# rename division_new  : -    Division\n",
    "\n",
    "WEEKLY_REPORT.rename(\n",
    "    columns={\"Division_new\": \"DIVISION\"},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "# drop duplicated value from division\n",
    "\n",
    "WEEKLY_REPORT.drop_duplicates(subset=['DIVISION'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA_COMPILATION_MERGE_WITHOUT_SSR = ALL_DATA_COMPILATION_MERGE[ALL_DATA_COMPILATION_MERGE['WORK ORDER TYPE'] != 'SSR']\n",
    "ALL_DATA_COMPILATION_MERGE_WITHOUT_SSR_COUNT = ALL_DATA_COMPILATION_MERGE_WITHOUT_SSR.groupby(['DIVISION'])['NEW METER NO'].count()\n",
    "\n",
    "\n",
    "#LEFT JOIN\n",
    "\n",
    "METER_WISE_DIVISION_COUNT_LEFT = pd.merge(ALL_DATA_COMPILATION_MERGE_WITHOUT_SSR_COUNT,WEEKLY_REPORT,left_on=['DIVISION'],right_on=['DIVISION'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILE_DATA_NB_SB = pd.concat([Infrastructure_Devices_NB, Infrastructure_Devices_SB], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Custom function to update meter numbers\n",
    "\n",
    "def update_meter_number(meter_number):\n",
    "    if meter_number.startswith('GP') or meter_number.startswith('GL'):\n",
    "        return 'GOE' + meter_number\n",
    "    elif meter_number.startswith('LT'):\n",
    "        return 'LNT' + meter_number\n",
    "    else:\n",
    "        return meter_number\n",
    "\n",
    "# Apply the custom function to each element in the 'METER NO.' column\n",
    "COMPILE_DATA_NB_SB['FULL_METER_NUMBER_INFRA'] = COMPILE_DATA_NB_SB['SerialNumber'].apply(update_meter_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ratan Kumar Jha\\AppData\\Local\\Temp\\ipykernel_10860\\3164480658.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  COMPILE_DATA_NB_SB['InstallationDatetime'] = pd.to_datetime(COMPILE_DATA_NB_SB['InstallationDatetime'])\n",
      "C:\\Users\\Ratan Kumar Jha\\AppData\\Local\\Temp\\ipykernel_10860\\3164480658.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  COMPILE_DATA_NB_SB['EntryDatetime'] = pd.to_datetime(COMPILE_DATA_NB_SB['EntryDatetime'])\n",
      "C:\\Users\\Ratan Kumar Jha\\AppData\\Local\\Temp\\ipykernel_10860\\3164480658.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  COMPILE_DATA_NB_SB['LastS05'] = pd.to_datetime(COMPILE_DATA_NB_SB['LastS05'])\n",
      "C:\\Users\\Ratan Kumar Jha\\AppData\\Local\\Temp\\ipykernel_10860\\3164480658.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  COMPILE_DATA_NB_SB['LastS02'] = pd.to_datetime(COMPILE_DATA_NB_SB['LastS02'])\n",
      "C:\\Users\\Ratan Kumar Jha\\AppData\\Local\\Temp\\ipykernel_10860\\3164480658.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  COMPILE_DATA_NB_SB['LastS04'] = pd.to_datetime(COMPILE_DATA_NB_SB['LastS04'])\n"
     ]
    }
   ],
   "source": [
    "COMPILE_DATA_NB_SB['InstallationDatetime'] = pd.to_datetime(COMPILE_DATA_NB_SB['InstallationDatetime'])\n",
    "COMPILE_DATA_NB_SB['EntryDatetime'] = pd.to_datetime(COMPILE_DATA_NB_SB['EntryDatetime'])\n",
    "COMPILE_DATA_NB_SB['LastS05'] = pd.to_datetime(COMPILE_DATA_NB_SB['LastS05'])\n",
    "COMPILE_DATA_NB_SB['LastS02'] = pd.to_datetime(COMPILE_DATA_NB_SB['LastS02'])\n",
    "COMPILE_DATA_NB_SB['LastS04'] = pd.to_datetime(COMPILE_DATA_NB_SB['LastS04'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
